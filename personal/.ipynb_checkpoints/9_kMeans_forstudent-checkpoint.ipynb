{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq_xfOABziep"
   },
   "source": [
    "# Week 10. Clustering \n",
    "\n",
    "## Exercise(1) Apply <font color='blue'>PCA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRdnAEkeziex",
    "outputId": "5ed192a6-7a88-4fd9-b556-7901c94954dc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('... loading data')\n",
    "with open('mnist.pkl', 'rb') as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_9EsVPeziez"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = train_set\n",
    "test_x, test_y = test_set\n",
    "\n",
    "train_x = pd.DataFrame(train_x)\n",
    "train_y = pd.DataFrame(train_y, columns=['label'])\n",
    "test_x = pd.DataFrame(test_x)\n",
    "test_y = pd.DataFrame(test_y, columns=['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_Vc9qM1zie0"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "# PCA_train_x = \n",
    "# PCA_test_x = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zqf7leDuzie0"
   },
   "outputs": [],
   "source": [
    "print('PCA_train_x shape: ', PCA_train_x.shape)\n",
    "print('PCA_test_x shape: ', PCA_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SsReldkpzie0"
   },
   "outputs": [],
   "source": [
    "## Plot on the graph\n",
    "# YOUR CODE STARTS HERE\n",
    "# plt.scatter(...)\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "\n",
    "plt.title('Visualizing MNIST through PCA', fontsize=24);\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IL3tNRiVzie0"
   },
   "source": [
    "### Let's use part of train_x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aax04iBzie1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "# sub_PCA_train_x = ...\n",
    "print('sub_PCA_train_x.shape: ', sub_PCA_train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "# sub_PCA_test_x = ...\n",
    "print('sub_PCA_test_x.shape: ', sub_PCA_test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOzSKNc-zie1"
   },
   "source": [
    "## Exercise(2) - Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jEVGDX-Gzie2"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "\n",
    "\n",
    "## Plot \n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(sub_PCA_train_x[:, 0], sub_PCA_train_x[:, 1], c=train_y['label'][:1000], cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar(boundaries=np.arange(11)-0.5).set_ticks(np.arange(10))\n",
    "plt.title(\"True label\")\n",
    "plt.xlabel('PC 1'); plt.ylabel('PC 2')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(sub_PCA_train_x[:, 0], sub_PCA_train_x[:, 1], c=pred_y, cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar(boundaries=np.arange(n_c+1)-0.5).set_ticks(np.arange(n_c))\n",
    "plt.title(\"Clustering with \" + li)\n",
    "plt.xlabel('PC 1'); plt.ylabel('PC 2')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoyAFIC2zie2"
   },
   "source": [
    "----\n",
    "## Exercise(3) k-means scratch\n",
    "### <font color='brown'>3-Step(1) Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GwnD0OOzie2",
    "outputId": "5fc18115-c2bb-4809-d2c4-3c6aedffd9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 4],\n",
       "       [1, 3, 4],\n",
       "       [1, 3, 4]])"
      ]
     },
     "execution_count": 440,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 3, 4])\n",
    "A = np.tile(a, (3,1))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_RJd-Vkzie3"
   },
   "source": [
    "k-means 클러스터링 알고리듬에 데이터를 제공하기 앞서 반드시 거쳐야하는 한 가지 중요한 작업은 데이터 내 여러 변수들의 변동폭(variations)을 일정하게 맞춰주는 것입니다. ML workflow 상에서는 이 과정을 **normalization** (정규화) 이라고 부릅니다.\n",
    "\n",
    "여기서는 일반적으로 사용되는 두 가지 normalization 방법을 살펴보고자 합니다.\n",
    "* min-max normalization\n",
    "* mean-std normalization\n",
    "\n",
    "다음의 함수들을 입력하여 data normalization을 할 수 있도록 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pk4DmKPvzie4"
   },
   "outputs": [],
   "source": [
    "def apply_normalizer(dataset, offset, divisor):\n",
    "    dataset_normalized = np.zeros(dataset.shape)\n",
    "    N = dataset.shape[0]\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # dataset_normalized = ...\n",
    "    # dataset_normalized = ...\n",
    "\n",
    "    return dataset_normalized\n",
    "\n",
    "\n",
    "def normalize_minmax(dataset):\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # minval = dataset.min(0)\n",
    "    # maxval = dataset.max(0)\n",
    "    \n",
    "    # dataset_normalized = ...\n",
    "\n",
    "    return dataset_normalized, minval, maxval-minval\n",
    "\n",
    "\n",
    "def normalize_meanstd(dataset):\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # meanval = ...\n",
    "    # stdval = ...\n",
    "\n",
    "    # dataset_normalized = ...\n",
    "\n",
    "    return dataset_normalized, meanval, stdval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JmmifihYzie4"
   },
   "outputs": [],
   "source": [
    "normalized_PCA_train_x, off, div = normalize_minmax(sub_PCA_train_x)\n",
    "print(\"Original data: \", sub_PCA_train_x[0], '\\nNormalized data: ', normalized_PCA_train_x[0])\n",
    "print(\"offset:\", off, \";  divisor:\", div, '\\n')\n",
    "\n",
    "normalized_PCA_train_x, off, div = normalize_meanstd(sub_PCA_train_x)\n",
    "print(\"Original data: \", sub_PCA_train_x[0], '\\nNormalized data: ', normalized_PCA_train_x[0])\n",
    "print(\"offset:\", off, \";  divisor:\", div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-Xqtw9Vzie4"
   },
   "outputs": [],
   "source": [
    "plt.scatter(normalized_PCA_train_x[:, 0], normalized_PCA_train_x[:, 1], cmap='Spectral', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1CCW2LPazie5"
   },
   "source": [
    " <font color='blue'>\n",
    "**Q1: 두 가지 normalization 방법에 대하여 각각 offset과 divisor가 갖는 의미가 무엇인가요?**<br>\n",
    "<font color='blue'>\n",
    "**Q2: 두 가지 normalization 방법에 대하여 각각, normalize 후에는 데이터의 범위가 어떻게 변하나요?** <br><br>\n",
    "\n",
    "\n",
    " <font color='black'>\n",
    "Hint: np.mean(X_normalized, axis=0), np.std(X_normalized, axis=0), np.min(X_normalized, axis=0), np.max(X_normalized, axis=0), np.median(X_normalized, axis=0) 등의 함수를 사용해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCT4LVDWzie5"
   },
   "outputs": [],
   "source": [
    "# a distance function\n",
    "def Euclidean_distance(vecA, vecB):\n",
    "    # YOUR CODE STARTS HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZyOdznkdzie5"
   },
   "source": [
    "### <font color='brown'>3-Step(2). Initialize centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wnASVGbzie5",
    "outputId": "705b1176-64e8-44b6-ba63-f5113984496a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many cluster do you want? 10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "k = int(input(\"How many cluster do you want? \"))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTzSYjxWzie6"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_initialize_centroids(centroids, dataset, k):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    k -- the number of clusters\n",
    "    centroids -- A dictionary of centroids\n",
    "    dataset -- Numpy array of PCA applied data\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    # init_centroids = ...\n",
    "    \n",
    "    # for ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAk7uzUwzie6"
   },
   "outputs": [],
   "source": [
    "def initialize_centroids(k, centroids, dataset):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    k -- the number of clusters\n",
    "    centroids -- A dictionary of centroids\n",
    "    dataset -- Numpy array of PCA applied data\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    for i in range(k):  # first k instances become the initial centroids\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XA-5YQ5Szie6"
   },
   "outputs": [],
   "source": [
    "centroids = {}\n",
    "\n",
    "# initialize_centroids(centroids, sub_PCA_train_x)\n",
    "random_initialize_centroids(centroids, sub_PCA_train_x, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hPX2l-Fkzie6"
   },
   "outputs": [],
   "source": [
    "## Change centroids value to dataframe. \n",
    "# cet_df = ...\n",
    "# cet_df.columns ...\n",
    "cet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozoSa-XZzie7"
   },
   "outputs": [],
   "source": [
    "## Plot random centroids on the dataset\n",
    "\n",
    "# YOUR CODE STARTS HERE\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4cuOVHYzie7"
   },
   "source": [
    "### <font color='brown'>3-Step(3). (Re)assigning every datas to its _closest centroid_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5yKtes8zie7"
   },
   "outputs": [],
   "source": [
    "def re_assgin_data(dataset, centroids, cluster_memberships):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    dataset -- Numpy array of PCA applied data\n",
    "    centroids -- A dictionary of centroids\n",
    "    cluster_memberships -- A dictionary data which is clustered by key\n",
    "                            (key: clustered group, value: values of that group)\n",
    "    \"\"\"\n",
    "    \n",
    "    # (Re)assigning every instance to its closest centroid\n",
    "    for row in dataset:\n",
    "        ## YOUR CODE STARTS HERE\n",
    "        # Calculate euclidean distance between each centroid and each data.\n",
    "        # distances_to_centroids = ...\n",
    "        \n",
    "        # Find the centroid with a minimum distance \n",
    "        # membership = ...\n",
    "        # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkYXnmuFzie7"
   },
   "source": [
    "### <font color='brown'>3-Step(4). Recalculate average of each cluster and calculate SSE value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_7vVyZ3zie8"
   },
   "outputs": [],
   "source": [
    "def re_calc_avg_calc_sse(curr_sse, cluster_memberships, centroids):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    curr_sse -- Current SSE value which is initiated by 0\n",
    "    cluster_memberships -- A dictionary data which is clustered by key(key: clustered group, value: values of that group)\n",
    "    centroids -- A dictionary of centroids\n",
    "    \"\"\"\n",
    "    \n",
    "    # Re-calculate the average of each cluster and calculate SSE.\n",
    "    for membership in cluster_memberships:\n",
    "        ## YOUR CODE STARTS HERE\n",
    "        # centroids[membership] = ...\n",
    "\n",
    "        for row in cluster_memberships[membership]:\n",
    "            # curr_sse += ...\n",
    "    \n",
    "    return curr_sse            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlmRwvMhzie8"
   },
   "source": [
    "###  <font color='brown'>3-Step(5). Iterate STEP3 and STEP4 until SSE is less than `tol` value \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfb1Sq3Hzie8"
   },
   "outputs": [],
   "source": [
    "## k-Means algorithm\n",
    "def kmeans(dataset, k, max_iter = 300, tol = 0.001):\n",
    "  \n",
    "    print('k is ', k)\n",
    "    centroids = {}\n",
    "    \n",
    "    ## YOUR CODE STARTS HERE\n",
    "    # ...\n",
    "    \n",
    "    ## 1. Initiate SSE which is key metric in k-means clustering (sse = sum of squared error) into 'np.inf'\n",
    "    curr_sse = np.inf\n",
    "\n",
    "    ## 2. Clustering\n",
    "    for i in range(max_iter):\n",
    "        cluster_memberships = {}\n",
    "\n",
    "        ## Initiate cluster memberships\n",
    "        for j in range(k):\n",
    "            cluster_memberships[j] = []\n",
    "\n",
    "        ## (Re)Aassign datas to its closest centroids\n",
    "        # ...\n",
    "\n",
    "        prev_sse = curr_sse\n",
    "        curr_sse = 0\n",
    "\n",
    "        ## Re-calculate the average of each cluster and calculate SSE.\n",
    "        # curr_sse = ...\n",
    "\n",
    "        ## Plot center points\n",
    "        plt.figure(i)\n",
    "        c_df = pd.DataFrame(centroids).transpose()\n",
    "        plt.scatter(c_df.loc[:, 0], c_df.loc[:, 1], color='black', marker='x')\n",
    "\n",
    "        ## Plot assigned data\n",
    "        for key in cluster_memberships:\n",
    "            plt.scatter(*zip(*cluster_memberships[key]), alpha=0.2)\n",
    "            plt.title('k={} '.format(k) + ' SSE=' + str(curr_sse))\n",
    "\n",
    "        plt.show()\n",
    "        '''\n",
    "        Stop iteration if \"(prev_sse - curr_sse) / curr_sse\" is less than 'tol' value. \n",
    "        It means you don't have to reassign datas since every data is already clustered.\n",
    "        '''    \n",
    "        print('iteration#{} | prev_sse= {:.4f};  curr_sse= {:.4f}'.format(i, prev_sse, curr_sse))\n",
    "        \n",
    "        if (prev_sse - curr_sse) / curr_sse < tol:\n",
    "            break\n",
    "\n",
    "    return cluster_memberships, curr_sse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYIduuPSzie9"
   },
   "source": [
    "\n",
    " <font color='blue'>\n",
    "**Q3: 함수의 초기값들을 살펴보세요. 위 함수가 시작할 때 centroids는 어떻게 지정되나요?**<br>\n",
    "**Q4: k-Means 알고리듬의 핵심 작동 원리는 (1) 근거리 우선을 원칙으로 하는 cluster 배정과 (2) 배정된 cluster members로부터 centroid를 새로 지정하는 과정을 반복하는 것에 있습니다. 위 함수에서 (1)과 (2)에 해당하는 부분이 각각 어디에 있나요?**<br>\n",
    "**Q5: 클러스터링의 품질을 나타내는 한 가지 척도(metric)는 sum of squared error (SSE) 이며, 위의 코드에서 curr_sse에 해당합니다. SSE가 같는 의미를 data와 centroids 관점에서 설명해보세요. SSE는 클수록 좋을까요, 작을수록 좋을까요?**<br>\n",
    "**Q6: 위 코드가 수행을 종료하는 기준은 무엇인가요? 변수 `tol`과 `max_iter`를 기준으로 설명해보세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dT0TvJjbzie9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# cluster_memberships, curr_sse = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQxzS1Xkzie9"
   },
   "source": [
    "----\n",
    "### Step(6) Using sklearn library\n",
    "- ___KMeans(n_clusters=)___ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bmTB-6Y8zie9"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "## YOUR CODE STARTS HERE\n",
    "# model = ...\n",
    "# ...\n",
    "\n",
    "# result = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKH87Sq6zie-"
   },
   "source": [
    "- Check ___crosstab___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wkxpv-6zie-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df = ...\n",
    "# ct = ...\n",
    "ct"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "9_kMeans_forstudent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
